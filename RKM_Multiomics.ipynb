{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef47d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import adata\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "import os\n",
    "import datetime\n",
    "import argparse\n",
    "import torch\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader\n",
    "import episcanpy.api as epi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abce13d",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "For more information check this [link](https://openproblems.bio/neurips_docs/about_tasks/task3_joint_embedding/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ad3781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openproblems_bmmc_multiome_phase2.censor_dataset.output_mod1.h5ad\r\n",
      "openproblems_bmmc_multiome_phase2.censor_dataset.output_mod2.h5ad\r\n",
      "openproblems_bmmc_multiome_phase2.censor_dataset.output_solution.h5ad\r\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "# !ls ~/arc_00077/raw_data/phase2-data/joint_embedding/openproblems_bmmc_multiome_phase2\n",
    "# ! cd ~/arc_00077/raw_data/phase2-data/joint_embedding/openproblems_bmmc_multiome_phase2\n",
    "! ls /user/leuven/331/vsc33180/arc_00077/raw_data/phase2-data/joint_embedding/openproblems_bmmc_multiome_phase2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a3f3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openproblems_bmmc_multiome_phase2.censor_dataset.output_mod1.h5ad',\n",
       " 'openproblems_bmmc_multiome_phase2.censor_dataset.output_mod2.h5ad',\n",
       " 'openproblems_bmmc_multiome_phase2.censor_dataset.output_solution.h5ad']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"/user/leuven/331/vsc33180/arc_00077/raw_data/phase2-data/joint_embedding/openproblems_bmmc_multiome_phase2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41ea16b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Your filename has more than two extensions: ['.censor_dataset', '.output_mod2', '.h5ad'].\n",
      "Only considering the two last: ['.output_mod2', '.h5ad'].\n",
      "WARNING: Your filename has more than two extensions: ['.censor_dataset', '.output_mod2', '.h5ad'].\n",
      "Only considering the two last: ['.output_mod2', '.h5ad'].\n"
     ]
    }
   ],
   "source": [
    "data_folder_path = \"/user/leuven/331/vsc33180/arc_00077/raw_data/phase2-data/joint_embedding/openproblems_bmmc_multiome_phase2/\"\n",
    "files = os.listdir(data_folder_path)\n",
    "# print(data_folder_path + files[0])\n",
    "data1 = sc.read_h5ad(data_folder_path + files[0])\n",
    "data2 = sc.read(data_folder_path + files[1])\n",
    "# data3 = sc.read(data_folder_path + files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5902bd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 42492 × 13431\n",
      "    obs: 'batch', 'size_factors'\n",
      "    var: 'gene_ids', 'feature_types'\n",
      "    uns: 'dataset_id', 'organism'\n",
      "    layers: 'counts'\n",
      "AnnData object with n_obs × n_vars = 42492 × 116490\n",
      "    obs: 'batch'\n",
      "    var: 'feature_types'\n",
      "    uns: 'dataset_id', 'gene_activity_var_names', 'organism'\n",
      "    obsm: 'gene_activity'\n",
      "    layers: 'counts'\n"
     ]
    }
   ],
   "source": [
    "print(data1)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f477fb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINC01128</th>\n",
       "      <th>KLHL17</th>\n",
       "      <th>ISG15</th>\n",
       "      <th>C1orf159</th>\n",
       "      <th>CDK11B</th>\n",
       "      <th>SLC35E2B</th>\n",
       "      <th>CDK11A</th>\n",
       "      <th>PEX10</th>\n",
       "      <th>PLCH2</th>\n",
       "      <th>TPRG1L</th>\n",
       "      <th>...</th>\n",
       "      <th>MT-ATP8</th>\n",
       "      <th>MT-ATP6</th>\n",
       "      <th>MT-CO3</th>\n",
       "      <th>MT-ND3</th>\n",
       "      <th>MT-ND4L</th>\n",
       "      <th>MT-ND4</th>\n",
       "      <th>MT-ND5</th>\n",
       "      <th>MT-ND6</th>\n",
       "      <th>MT-CYB</th>\n",
       "      <th>AL592183.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.688304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.688304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.688304</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.161511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.161511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.651025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344029</td>\n",
       "      <td>0.599516</td>\n",
       "      <td>1.455109</td>\n",
       "      <td>0.344029</td>\n",
       "      <td>0.344029</td>\n",
       "      <td>0.599516</td>\n",
       "      <td>0.802834</td>\n",
       "      <td>0.344029</td>\n",
       "      <td>1.455109</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.355826</td>\n",
       "      <td>2.527316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.911013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.556855</td>\n",
       "      <td>2.646429</td>\n",
       "      <td>1.054988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.556855</td>\n",
       "      <td>1.054988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.337923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LINC01128  KLHL17  ISG15  C1orf159    CDK11B  SLC35E2B  CDK11A  PEX10  \\\n",
       "0        0.0     0.0    0.0       0.0  0.000000       0.0     0.0    0.0   \n",
       "1        0.0     0.0    0.0       0.0  1.161511       0.0     0.0    0.0   \n",
       "2        0.0     0.0    0.0       0.0  0.000000       0.0     0.0    0.0   \n",
       "3        0.0     0.0    0.0       0.0  0.000000       0.0     0.0    0.0   \n",
       "4        0.0     0.0    0.0       0.0  0.000000       0.0     0.0    0.0   \n",
       "\n",
       "   PLCH2  TPRG1L  ...   MT-ATP8   MT-ATP6    MT-CO3    MT-ND3   MT-ND4L  \\\n",
       "0    0.0     0.0  ...  0.000000  0.000000  0.000000  1.688304  0.000000   \n",
       "1    0.0     0.0  ...  0.000000  0.000000  1.161511  0.000000  0.000000   \n",
       "2    0.0     0.0  ...  0.344029  0.599516  1.455109  0.344029  0.344029   \n",
       "3    0.0     0.0  ...  0.000000  1.355826  2.527316  0.000000  0.000000   \n",
       "4    0.0     0.0  ...  0.000000  1.556855  2.646429  1.054988  0.000000   \n",
       "\n",
       "     MT-ND4    MT-ND5    MT-ND6    MT-CYB  AL592183.1  \n",
       "0  1.688304  0.000000  0.000000  1.688304         0.0  \n",
       "1  0.000000  0.000000  0.000000  2.651025         0.0  \n",
       "2  0.599516  0.802834  0.344029  1.455109         0.0  \n",
       "3  0.000000  1.911013  0.000000  0.000000         0.0  \n",
       "4  1.556855  1.054988  0.000000  2.337923         0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(data1.var[\"feature_types\"])\n",
    "rna = pd.DataFrame.sparse.from_spmatrix(data1.X) # 42492 x 13431\n",
    "rna.columns = data1.var.index #data1.var[\"gene_ids\"] -> ENSEMBL IDs\n",
    "\n",
    "sc.pp.highly_variable_genes(data1, n_top_genes=5000) # Find HGVs\n",
    "rna = rna.transpose().loc[data1.var[\"highly_variable\"] == True].transpose()\n",
    "rna.head() # 42492 x 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d75059d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr1-629497-630394</th>\n",
       "      <th>chr1-633515-634474</th>\n",
       "      <th>chr1-778276-779191</th>\n",
       "      <th>chr1-827067-827948</th>\n",
       "      <th>chr1-958865-959755</th>\n",
       "      <th>chr1-1013003-1013921</th>\n",
       "      <th>chr1-1019151-1019993</th>\n",
       "      <th>chr1-1032734-1033630</th>\n",
       "      <th>chr1-1059182-1060025</th>\n",
       "      <th>chr1-1068898-1069703</th>\n",
       "      <th>...</th>\n",
       "      <th>chrX-154478646-154479538</th>\n",
       "      <th>chrX-154490306-154491212</th>\n",
       "      <th>chrX-154515887-154516793</th>\n",
       "      <th>chrX-154546772-154547705</th>\n",
       "      <th>chrX-154762342-154763226</th>\n",
       "      <th>chrX-155026531-155027401</th>\n",
       "      <th>chrX-155070906-155071798</th>\n",
       "      <th>chrX-155215991-155216852</th>\n",
       "      <th>GL000219.1-99257-100160</th>\n",
       "      <th>KI270713.1-21434-22336</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chr1-629497-630394  chr1-633515-634474  chr1-778276-779191  \\\n",
       "0                 0.0                 1.0                 0.0   \n",
       "1                 1.0                 1.0                 0.0   \n",
       "2                 0.0                 1.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 1.0                 0.0   \n",
       "\n",
       "   chr1-827067-827948  chr1-958865-959755  chr1-1013003-1013921  \\\n",
       "0                 0.0                 0.0                   0.0   \n",
       "1                 1.0                 0.0                   0.0   \n",
       "2                 0.0                 1.0                   1.0   \n",
       "3                 0.0                 0.0                   1.0   \n",
       "4                 0.0                 1.0                   0.0   \n",
       "\n",
       "   chr1-1019151-1019993  chr1-1032734-1033630  chr1-1059182-1060025  \\\n",
       "0                   0.0                   0.0                   1.0   \n",
       "1                   1.0                   0.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   0.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   chr1-1068898-1069703  ...  chrX-154478646-154479538  \\\n",
       "0                   0.0  ...                       1.0   \n",
       "1                   0.0  ...                       0.0   \n",
       "2                   0.0  ...                       0.0   \n",
       "3                   1.0  ...                       0.0   \n",
       "4                   1.0  ...                       0.0   \n",
       "\n",
       "   chrX-154490306-154491212  chrX-154515887-154516793  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   chrX-154546772-154547705  chrX-154762342-154763226  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       1.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   chrX-155026531-155027401  chrX-155070906-155071798  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       1.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   chrX-155215991-155216852  GL000219.1-99257-100160  KI270713.1-21434-22336  \n",
       "0                       0.0                      1.0                     0.0  \n",
       "1                       0.0                      0.0                     0.0  \n",
       "2                       0.0                      0.0                     0.0  \n",
       "3                       0.0                      0.0                     0.0  \n",
       "4                       0.0                      0.0                     0.0  \n",
       "\n",
       "[5 rows x 10002 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epi.pp.select_var_feature(data2, nb_features=10000, show=False) # Inplace select 10000 variable regions\n",
    "atac = pd.DataFrame.sparse.from_spmatrix(data2.X)\n",
    "atac.columns = data2.var.index\n",
    "atac.head() # 42492 x 10002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa95f63",
   "metadata": {},
   "source": [
    "## Setting up the necessary arguments and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0113e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tb\n",
    "# # Model Settings =================================================================================================\n",
    "# parser = argparse.ArgumentParser(description='Gen-RKM Model')\n",
    "\n",
    "# parser.add_argument('--N', type=int, default=1000, help='Total # of samples')\n",
    "# parser.add_argument('--mb_size', type=int, default=300, help='Mini-batch size. See utils.py')\n",
    "# parser.add_argument('--h_dim', type=int, default=2, help='Dim of latent vector') # shared latent space\n",
    "# parser.add_argument('--capacity', type=int, default=32, help='Capacity of network. See utils.py') # important in CNNs\n",
    "# parser.add_argument('--x_fdim', type=int, default=128, help='Input x_fdim. See utils.py') # feature map dimensionality\n",
    "# parser.add_argument('--y_fdim', type=int, default=20, help='Input y_fdim. See utils.py') # feature map dimensionality\n",
    "# parser.add_argument('--c_accu', type=float, default=100, help='Input weight on recons_error')\n",
    "\n",
    "# # Training Settings =============================\n",
    "# parser.add_argument('--lr', type=float, default=1e-4, help='Input learning rate for optimizer')\n",
    "# parser.add_argument('--max_epochs', type=int, default=100, help='Input max_epoch for cut-off')\n",
    "# # parser.add_argument('--device', type=str, default='cuda', help='Device type: cuda or cpu')\n",
    "# parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu', help='Device type: cuda or cpu')\n",
    "# parser.add_argument('--workers', type=int, default=0, help='# of workers for dataloader')\n",
    "# parser.add_argument('--shuffle', type=bool, default=True, help='shuffle dataset: true or false')\n",
    "\n",
    "# opt = parser.parse_args()\n",
    "args = {\n",
    "    \"N\": rna.shape[0],\n",
    "#     \"mb_size\": 300,\n",
    "    \"h_dim\": 32,\n",
    "    \"capacity\": 32,\n",
    "    \"x_fdim\": 128,\n",
    "    \"y_fdim\": 256,\n",
    "    \"c_accu\": 100,\n",
    "    \"lr\": 1e-6,\n",
    "    \"max_epochs\": 1,\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"workers\": 15,\n",
    "    \"shuffle\": True,\n",
    "    \"batch_size\": 100,\n",
    "}\n",
    "opt = args\n",
    "# print(opt[\"mb_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kPCA(X, Y):\n",
    "#     print(X)\n",
    "#     print(Y)\n",
    "    a = torch.mm(X, torch.t(X)) + torch.mm(Y, torch.t(Y))\n",
    "    nh1 = a.size(0)\n",
    "    oneN = torch.div(torch.ones(nh1, nh1), nh1).float().to(opt[\"device\"])\n",
    "    a = a - torch.mm(oneN, a) - torch.mm(a, oneN) + torch.mm(torch.mm(oneN, a), oneN)  # centering\n",
    "    print(a)\n",
    "#     print(a, end=\"\\r\")\n",
    "    h, s, _ = torch.svd(a, some=False)\n",
    "    return h[:, :opt[\"h_dim\"]], s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc0535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy function\n",
    "def rkm_loss(output1, X, output2, Y):\n",
    "    h, s = kPCA(output1, output2)\n",
    "    U = torch.mm(torch.t(output1), h)\n",
    "    V = torch.mm(torch.t(output2), h)\n",
    "\n",
    "    x_tilde = net3(torch.mm(h, torch.t(U))) # NET3\n",
    "    y_tilde = net4(torch.mm(h, torch.t(V))) # NET4\n",
    "\n",
    "    # Costs\n",
    "    f1 = torch.trace(torch.mm(torch.mm(output1, U), torch.t(h))) + torch.trace(\n",
    "        torch.mm(torch.mm(output2, V), torch.t(h)))\n",
    "    f2 = 0.5 * torch.trace(torch.mm(h, torch.mm(torch.diag(s[:opt[\"h_dim\"]]), torch.t(h))))\n",
    "    f3 = 0.5 * ((torch.trace(torch.mm(torch.t(U), U))) + (torch.trace(torch.mm(torch.t(V), V))))\n",
    "    recon_loss = torch.nn.MSELoss()\n",
    "    f4 = recon_loss(x_tilde, X) + recon_loss(y_tilde, Y)  # reconstruction loss\n",
    "\n",
    "    loss = - f1 + f3 + f2 + 0.5 * (- f1 + f3 + f2) ** 2 + opt[\"c_accu\"] * f4  # stabilized loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b46335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_dirs:\n",
    "    \"\"\" Creates directories for Checkpoints and saving trained models \"\"\"\n",
    "\n",
    "    def __init__(self, ct):\n",
    "        self.ct = ct\n",
    "        self.dircp = 'checkpoint.pth_{}.tar'.format(self.ct)\n",
    "        self.dirout = 'Mul_trained_RKM_{}.tar'.format(self.ct)\n",
    "\n",
    "    def create(self):\n",
    "        if not os.path.exists('cp/'):\n",
    "            os.makedirs('cp/')\n",
    "\n",
    "        if not os.path.exists('out/'):\n",
    "            os.makedirs('out/')\n",
    "\n",
    "    def save_checkpoint(self, state, is_best):\n",
    "        if is_best:\n",
    "            torch.save(state, 'cp/{}'.format(self.dircp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbda73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/dataloader-access-two-items-at-the-same-time/22664\n",
    "class ConcatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset1, dataset2):\n",
    "#         self.dataset1 = dataset1 # datasets should be sorted!\n",
    "#         self.dataset2 = dataset2\n",
    "\n",
    "        self.dataset1 = torch.tensor(dataset1.values) # datasets should be sorted!\n",
    "        self.dataset2 = torch.tensor(dataset2.values)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         x1 = self.dataset1.loc[index].to_numpy() #loc, que no iloc (puede que iloc funcione)\n",
    "#         x2 = self.dataset2.loc[index].to_numpy()\n",
    "        \n",
    "        x1 = self.dataset1[index].float()\n",
    "        x2 = self.dataset2[index].float()\n",
    "\n",
    "        return x1, x2, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset1) # assuming both datasets have same length\n",
    "    \n",
    "# print(\"Hello\")\n",
    "train_loader = DataLoader(\n",
    "             ConcatDataset(rna, atac),\n",
    "             batch_size=args[\"batch_size\"], shuffle=args[\"shuffle\"],\n",
    "             num_workers=args[\"workers\"]\n",
    "            )\n",
    "# print(\"There\")\n",
    "\n",
    "# initial_time = datetime.datetime.now()\n",
    "# for i, (datax, datay, index) in enumerate(train_loader):\n",
    "#     if i==0:\n",
    "#         initial_time_first_iteration = datetime.datetime.now()\n",
    "#     print(i)\n",
    "#     print(datax.shape)\n",
    "#     print(datay.shape)\n",
    "#     if i==2:\n",
    "#         break\n",
    "        \n",
    "# print(\"It took {} min overall.\".format(datetime.datetime.now()-initial_time))\n",
    "# print(\"It took {} min from the first iteration.\".format(datetime.datetime.now()-initial_time_first_iteration))\n",
    "\n",
    "# num_workers = 5 -> It took 0:08:38.815087 min.\n",
    "# num_workers = 15 -> It took 0:11:13.346173 min overall - It took 0:01:15.955870 min from the first iteration.\n",
    "# num_workers = 24 -> It took 0:16:11.308331 min overall - It took 0:02:02.066693 min from the first iteration\n",
    "# num_workers = 48 -> It took 0:40:50.197775 min overall - It took 0:04:59.826997 min from the first iteration\n",
    "# Estos 4 de arriba se han hecho con pandas df, los de abajo con tensores\n",
    "# num_workers = 0 -> It took 0:00:20.585820 min overall - It took 0:00:13.921048 min from the first iteration\n",
    "# num_workers = 5 -> It took 0:00:35.032580 min overall - It took 0:00:12.420856 min from the first iteration\n",
    "# num_workers = 15 -> It took 0:00:47.020544 min overall - It took 0:00:05.366418 min from the first iteration\n",
    "# num_workers = 24 -> It took 0:02:04.082042 min overall - It took 0:00:07.720705 min from the first iteration.\n",
    "# num_workers = 24 -> It took 0:01:13.212152 min overall - It took 0:00:17.465964 min from the first iteration.\n",
    "# num_workers = 48 -> It took 0:03:54.132624 min overall - It took 0:00:42.083046 min from the first iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39416ea9",
   "metadata": {},
   "source": [
    "## Setting up the NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a3c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net1(nn.Module): # Phi 1 - RNA to feature map\n",
    "#     def __init__(self, input_dim, hidden_dim, args):\n",
    "#         super(Net1, self).__init__()\n",
    "# #         c = capacity\n",
    "#         self.linear1 = nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "#         self.linear2 = nn.Linear(in_features=hidden_dim, out_features=args[\"x_fdim\"])\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.linear1(x)\n",
    "#         x = F.leaky_relu(x, negative_slope=0.2)\n",
    "#         x = self.linear2(x)\n",
    "# #         x = F.leaky_relu(x, negative_slope=0.2)\n",
    "\n",
    "#         return x\n",
    "\n",
    "class Net1(nn.Module): # Phi 1 - RNA to feature map\n",
    "    def __init__(self, input_dim, hidden_dim_list, args):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.transformations = nn.ModuleList()\n",
    "        self.transformations.append(nn.Linear(in_features=input_dim, out_features=hidden_dim_list[0]))\n",
    "        \n",
    "        for i in range(len(hidden_dim_list)):\n",
    "            if i == len(hidden_dim_list)-1:\n",
    "                dim = hidden_dim_list[-1]\n",
    "                self.transformations.append(nn.Linear(in_features=dim, out_features=args[\"x_fdim\"]))\n",
    "                \n",
    "            else:\n",
    "                in_dim, out_dim = hidden_dim_list[i], hidden_dim_list[i+1]\n",
    "                self.transformations.append(nn.Linear(in_features=in_dim, out_features=out_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, transform in enumerate(self.transformations):\n",
    "            if i == len(self.transformations)-1:\n",
    "                x = transform(x)\n",
    "                # No leaky relu at the end\n",
    "                \n",
    "            else:\n",
    "                x = transform(x)\n",
    "                x = F.leaky_relu(x, negative_slope=0.2)\n",
    "    \n",
    "    \n",
    "    \n",
    "# class Net3(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, args): #Psi 1 - Feature map to RNA (input dim = 5000)\n",
    "#         super(Net3, self).__init__()\n",
    "#         self.linear2t = nn.Linear(in_features=args[\"x_fdim\"], out_features=hidden_dim)\n",
    "#         self.linear1t = nn.Linear(in_features=hidden_dim, out_features=input_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.linear2t(x)\n",
    "#         x = F.leaky_relu(x, negative_slope=0.2)\n",
    "#         x = self.linear1t(x)\n",
    "#         x = F.relu(x) # RNA preprocessed has a lower bound of 0\n",
    "\n",
    "#         return x\n",
    "    \n",
    "class Net3(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_list, args): #Psi 1 - Feature map to RNA (input dim = 5000)\n",
    "        super(Net3, self).__init__()\n",
    "        \n",
    "        hidden_dim_list.reverse() # Reverse the list to be the inverse of Net 1\n",
    "        self.reverse_transformations = nn.ModuleList()\n",
    "        self.reverse_transformations.append(nn.Linear(in_features=args[\"x_fdim\"], out_features=hidden_dim_list[0]))\n",
    "        \n",
    "        for i in range(len(hidden_dim_list)):\n",
    "            if i == len(hidden_dim_list)-1:\n",
    "                dim = hidden_dim_list[-1]\n",
    "                self.reverse_transformations.append(nn.Linear(in_features=dim, out_features=input_dim))\n",
    "                \n",
    "            else:\n",
    "                in_dim, out_dim = hidden_dim_list[i], hidden_dim_list[i+1]\n",
    "                self.reverse_transformations.append(nn.Linear(in_features=in_dim, out_features=out_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, transform in enumerate(self.reverse_transformations):\n",
    "            if i == len(self.reverse_transformations)-1:\n",
    "                x = transform(x)\n",
    "                x = F.relu(x) # RNA preprocessed has a lower bound of 0\n",
    "                \n",
    "            else:\n",
    "                x = transform(x)\n",
    "                x = F.leaky_relu(x, negative_slope=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de89955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module): # Phi 2 - ATAC to feature map\n",
    "    def __init__(self, input_dim, hidden_dim_list, args): \n",
    "        super(Net2, self).__init__()\n",
    "#         c = capacity\n",
    "        self.transformations = nn.ModuleList()\n",
    "        self.transformations.append(nn.Linear(in_features=input_dim, out_features=hidden_dim_list[0]))\n",
    "        \n",
    "        for i in range(len(hidden_dim_list)):\n",
    "            if i == len(hidden_dim_list)-1:\n",
    "                dim = hidden_dim_list[-1]\n",
    "                self.transformations.append(nn.Linear(in_features=dim, out_features=args[\"x_fdim\"]))\n",
    "                \n",
    "            else:\n",
    "                in_dim, out_dim = hidden_dim_list[i], hidden_dim_list[i+1]\n",
    "                self.transformations.append(nn.Linear(in_features=in_dim, out_features=out_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, transform in enumerate(self.transformations):\n",
    "            if i == len(self.transformations)-1:\n",
    "                x = transform(x)\n",
    "                # No leaky relu at the end\n",
    "                \n",
    "            else:\n",
    "                x = transform(x)\n",
    "                x = F.leaky_relu(x, negative_slope=0.2)\n",
    "\n",
    "# class Net2(nn.Module): # Phi 2 - ATAC to feature map\n",
    "#     def __init__(self, input_dim, hidden_dim_list, args): \n",
    "#         super(Net2, self).__init__()\n",
    "# #         c = capacity\n",
    "#         self.linear1 = nn.Linear(in_features=input_dim,out_features=hidden_dim_list[0])\n",
    "#         self.linear2 = nn.Linear(in_features=hidden_dim_list[0], out_features=hidden_dim_list[1])\n",
    "#         self.linear3 = nn.Linear(in_features=hidden_dim_list[1], out_features=args[\"y_fdim\"])\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.linear1(x)\n",
    "#         x = F.leaky_relu(x, negative_slope=0.2)\n",
    "#         x = self.linear2(x)\n",
    "#         x = F.leaky_relu(x, negative_slope=0.2)\n",
    "#         x = self.linear3(x)        \n",
    "# #         x = F.leaky_relu(x, negative_slope=0.2)\n",
    "\n",
    "#         return x   \n",
    "\n",
    "class Net4(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_list, args): #Psi 2 - Feature map to ATAC (input dim = 116490)\n",
    "        super(Net4, self).__init__()\n",
    "    \n",
    "        hidden_dim_list.reverse() # Reverse the list to be the inverse of Net 2\n",
    "        self.reverse_transformations = nn.ModuleList()\n",
    "        self.reverse_transformations.append(nn.Linear(in_features=args[\"x_fdim\"], out_features=hidden_dim_list[0]))\n",
    "        \n",
    "        for i in range(len(hidden_dim_list)):\n",
    "            if i == len(hidden_dim_list)-1:\n",
    "                dim = hidden_dim_list[-1]\n",
    "                self.reverse_transformations.append(nn.Linear(in_features=dim, out_features=input_dim))\n",
    "                \n",
    "            else:\n",
    "                in_dim, out_dim = hidden_dim_list[i], hidden_dim_list[i+1]\n",
    "                self.reverse_transformations.append(nn.Linear(in_features=in_dim, out_features=out_dim))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, transform in enumerate(self.reverse_transformations):\n",
    "            if i == len(self.reverse_transformations)-1:\n",
    "                x = transform(x)\n",
    "                x = torch.sigmoid(x) # ATAC is has binary values\n",
    "                \n",
    "            else:\n",
    "                x = transform(x)\n",
    "                x = F.leaky_relu(x, negative_slope=0.2)        \n",
    "        \n",
    "# class Net4(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim_list, args): #Psi 2 - Feature map to ATAC (input dim = 116490)\n",
    "#         super(Net4, self).__init__()        \n",
    "#         self.linear3t = nn.Linear(in_features=args[\"y_fdim\"], out_features=hidden_dim_list[1])\n",
    "#         self.linear2t = nn.Linear(in_features=hidden_dim_list[1], out_features=hidden_dim_list[0])\n",
    "#         self.linear1t = nn.Linear(in_features=hidden_dim_list[0], out_features=input_dim)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.linear3t(x)\n",
    "#         x = F.leaky_relu(x, negative_slope=0.2)\n",
    "#         x = self.linear2t(x)\n",
    "#         x = F.leaky_relu(x, negative_slope=0.2)\n",
    "#         x = self.linear1t(x)\n",
    "#         x = torch.sigmoid(x) # ATAC is has binary values\n",
    "\n",
    "#         return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = {\"x_fdim\":2}\n",
    "# hid = [1000, 500, 300, 200, 50, 10]\n",
    "# inp = 10000\n",
    "# n2 = Net2(inp, hid, args)\n",
    "# n4 = Net4(inp, hid, args)\n",
    "# print(n2.transformations)\n",
    "# print(n4.reverse_transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_compute(data, net1, net2, kPCA, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "    \"\"\" Function to compute embeddings of full dataset. \"\"\"\n",
    "    # Data is a dictionary with keys RNA and ATAC\n",
    "#     args[\"shuffle\"] = False\n",
    "#     xt, _, _ = get_mnist_dataloader(args=args)  # loading data without shuffle\n",
    "    xt = data[\"RNA\"]\n",
    "    yt = data[\"ATAC\"]\n",
    "    xtr = net1(xt.to(args.device))\n",
    "    ytr = net2(yt.to(args.device)) # This was targets at first, but we don't have labels\n",
    "\n",
    "    h, s = kPCA(xtr, ytr)\n",
    "    return torch.mm(torch.t(xtr), h), torch.mm(torch.t(ytr), h), h, s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0267f3",
   "metadata": {},
   "source": [
    "## Initialize nets and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ae40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net1 = Net1(input_dim=5000, hidden_dim=1000, args=args).float().to(opt[\"device\"]) # input_dim, hidden_dim, args\n",
    "# net2 = Net2(input_dim=116490, hidden_dim_list=[10000, 2000], args=args).float().to(opt[\"device\"]) # input_dim, hidden_dim_list, args\n",
    "# net3 = Net3(input_dim=5000, hidden_dim=1000, args=args).float().to(opt[\"device\"]) # input_dim, hidden_dim, args\n",
    "# net4 = Net4(input_dim=116490, hidden_dim_list=[10000, 2000], args=args).float().to(opt[\"device\"]) # input_dim, hidden_dim_list, args\n",
    "# net4 = Net4(input_dim=116490, hidden_dim_list=[10000, 2000], args=args).double().to(opt[\"device\"])\n",
    "\n",
    "hidden_list_rna = [3000, 1000, 500, 64]\n",
    "hidden_list_atac = [50000, 25000, 10000, 5000, 2500, 1000, 500, 64]\n",
    "net1 = Net1(input_dim=5000, hidden_dim_list=hidden_list_rna, args=args).float().to(opt[\"device\"]) # input_dim, hidden_dim, args\n",
    "net2 = Net2(input_dim=116490, hidden_dim_list=, args=args).float().to(opt[\"device\"]) # input_dim, hidden_dim_list, args\n",
    "net3 = Net3(input_dim=5000, hidden_dim_list=hidden_list_rna, args=args).float().to(opt[\"device\"]) # input_dim, hidden_dim, args\n",
    "net4 = Net4(input_dim=116490, hidden_dim_list=, args=args).float().to(opt[\"device\"])\n",
    "\n",
    "params = list(net1.parameters()) + list(net3.parameters()) + list(net2.parameters()) + list(net4.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=opt[\"lr\"], weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefbc816",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = time.strftime(\"%Y%m%d-%H%M\")\n",
    "dirs = create_dirs(ct=ct)\n",
    "dirs.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cef1e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_cost = 6  # Costs from where checkpoints will be saved\n",
    "t = 1\n",
    "cost = np.inf  # Initialize cost\n",
    "start = datetime.datetime.now()\n",
    "while cost > 0.2 and t <= opt[\"max_epochs\"]:  # run epochs until convergence\n",
    "    avg_loss = 0\n",
    "    for i, (datax, datay, _) in enumerate(train_loader):\n",
    "        if i < math.ceil(opt[\"N\"] / opt[\"batch_size\"]):\n",
    "#             print(f'On step {i}', end=\"\\r\")\n",
    "            print(f'On step {i}')\n",
    "            datax, datay = datax.float().to(opt[\"device\"]), datay.float().to(opt[\"device\"])\n",
    "            output1 = net1(datax.float())\n",
    "            output2 = net2(datay.float())\n",
    "            loss = rkm_loss(output1, datax, output2, datay).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(parameters=params, max_norm=1)\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.detach().cpu().numpy()\n",
    "        \n",
    "        else:\n",
    "            break\n",
    "    cost = avg_loss\n",
    "\n",
    "    # Remember lowest cost and save checkpoint\n",
    "    is_best = cost < l_cost\n",
    "    l_cost = min(cost, l_cost)\n",
    "\n",
    "    dirs.save_checkpoint({\n",
    "        'epochs': t + 1,\n",
    "        'net1_state_dict': net1.state_dict(),\n",
    "        'net3_state_dict': net3.state_dict(),\n",
    "        'net2_state_dict': net2.state_dict(),\n",
    "        'net4_state_dict': net4.state_dict(),\n",
    "        'l_cost': l_cost,\n",
    "        'optimizer': optimizer.state_dict()}, is_best)\n",
    "    print(f\"Epoch: {t}, Cost: {cost}\")\n",
    "    t += 1\n",
    "print('Finished Training in: {}. Lowest cost: {}'.format(str(datetime.datetime.now() - start), l_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723f927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # net1(datax.float())\n",
    "# output1 = net1(datax.double()).double()\n",
    "# output2 = net2(datay.double()).double()\n",
    "# print(output1)\n",
    "# print(output2)\n",
    "# loss = rkm_loss(output1, datax, output2, datay).double()\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://discuss.pytorch.org/t/train-simultaneously-on-two-datasets/649\n",
    "# # class ConcatDataset(torch.utils.data.Dataset):\n",
    "# #     def __init__(self, *datasets):\n",
    "# # #         self.datasets = datasets\n",
    "# #         self.datasets = [torch.tensor(dataset.values) for dataset in datasets]\n",
    "\n",
    "# #     def __getitem__(self, i):\n",
    "# #         return tuple(d[i] for d in self.datasets)\n",
    "\n",
    "# #     def __len__(self):\n",
    "# #         return min(len(d) for d in self.datasets)\n",
    "\n",
    "# # import multiprocessing\n",
    "\n",
    "# # %time\n",
    "# # https://discuss.pytorch.org/t/dataloader-access-two-items-at-the-same-time/22664\n",
    "# class ConcatDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, dataset1, dataset2):\n",
    "# #         self.dataset1 = dataset1 # datasets should be sorted!\n",
    "# #         self.dataset2 = dataset2\n",
    "\n",
    "#         self.dataset1 = torch.tensor(dataset1.values) # datasets should be sorted!\n",
    "#         self.dataset2 = torch.tensor(dataset2.values)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "# #         print(index)\n",
    "# #         print(type(index))\n",
    "# #         print(type(self.dataset1.loc[index].values))\n",
    "# #         x1 = self.dataset1.loc[index].to_numpy() #loc, que no iloc (puede que iloc funcione)\n",
    "# #         x2 = self.dataset2.loc[index].to_numpy()\n",
    "        \n",
    "#         x1 = self.dataset1[index]\n",
    "#         x2 = self.dataset2[index]\n",
    "\n",
    "#         return x1, x2, index\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset1) # assuming both datasets have same length\n",
    "\n",
    "# print(\"Hello\")\n",
    "# train_loader = DataLoader(\n",
    "#              ConcatDataset(rna, atac),\n",
    "#              batch_size=args[\"batch_size\"], shuffle=args[\"shuffle\"],\n",
    "#              num_workers=48 #args[\"workers\"]\n",
    "#             )\n",
    "# print(\"There\")\n",
    "\n",
    "# initial_time = datetime.datetime.now()\n",
    "# for i, (datax, datay, index) in enumerate(train_loader):\n",
    "#     if i==0:\n",
    "#         initial_time_first_iteration = datetime.datetime.now()\n",
    "#     print(i)\n",
    "#     print(datax.shape)\n",
    "#     print(datay.shape)\n",
    "#     if i==2:\n",
    "#         break\n",
    "        \n",
    "# print(\"It took {} min overall.\".format(datetime.datetime.now()-initial_time))\n",
    "# print(\"It took {} min from the first iteration.\".format(datetime.datetime.now()-initial_time_first_iteration))\n",
    "\n",
    "# num_workers = 5 -> It took 0:08:38.815087 min.\n",
    "# num_workers = 15 -> It took 0:11:13.346173 min overall - It took 0:01:15.955870 min from the first iteration.\n",
    "# num_workers = 24 -> It took 0:16:11.308331 min overall - It took 0:02:02.066693 min from the first iteration\n",
    "# num_workers = 48 -> It took 0:40:50.197775 min overall - It took 0:04:59.826997 min from the first iteration\n",
    "# Estos 4 de arriba se han hecho con pandas df, los de abajo con tensores\n",
    "# num_workers = 0 -> It took 0:00:20.585820 min overall - It took 0:00:13.921048 min from the first iteration\n",
    "# num_workers = 5 -> It took 0:00:35.032580 min overall - It took 0:00:12.420856 min from the first iteration\n",
    "# num_workers = 15 -> It took 0:00:47.020544 min overall - It took 0:00:05.366418 min from the first iteration\n",
    "# num_workers = 24 -> It took 0:02:04.082042 min overall - It took 0:00:07.720705 min from the first iteration.\n",
    "# num_workers = 24 -> It took 0:01:13.212152 min overall - It took 0:00:17.465964 min from the first iteration.\n",
    "# num_workers = 48 -> It took 0:03:54.132624 min overall - It took 0:00:42.083046 min from the first iteration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
